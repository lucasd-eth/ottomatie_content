import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

async function generateAnswer(query, context) {
  if (!query) throw new Error("Query is missing");
  if (!context) throw new Error("Context is missing");

  const prompt = `
Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn tÃ¬m kiáº¿m thÃ´ng tin tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u.
ğŸ’¡ **LÆ°u Ã½ quan trá»ng:**  
- **Tráº£ lá»i chÃ­nh xÃ¡c tá»«ng tá»« nhÆ° trong dá»¯ liá»‡u.**  
- **KhÃ´ng tÃ³m táº¯t, khÃ´ng rÃºt gá»n, khÃ´ng thay Ä‘á»•i ná»™i dung.**  
- **Giá»¯ nguyÃªn toÃ n bá»™ dáº¥u cÃ¢u vÃ  thá»© tá»± cÃ¢u.**  

ğŸ“š **ThÃ´ng tin tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u:**  
"""
${context}
"""

â“ **CÃ¢u há»i:** "${query}"  

âœ… **Tráº£ lá»i Ä‘áº§y Ä‘á»§, khÃ´ng thiáº¿u tá»« nÃ o:**
`.trim();

  try {
    console.log("ğŸ“ Prompt gá»­i OpenAI:\n", prompt);

    const response = await openai.completions.create({
      model: "gpt-3.5-turbo-instruct", // Hoáº·c "text-davinci-003"
      prompt: prompt,
      temperature: 0,
      max_tokens: 500, // TrÃ¡nh giá»›i háº¡n 16 tokens máº·c Ä‘á»‹nh
      top_p: 1,
      frequency_penalty: 0,
      presence_penalty: 0
    });

    const answer = response.choices[0]?.text.trim() || "KhÃ´ng cÃ³ káº¿t quáº£.";
    console.log("ğŸ“¢ Káº¿t quáº£ pháº£n há»“i tá»« OpenAI:", answer);

    return answer;
  } catch (error) {
    console.error("âŒ Error calling OpenAI API:", error);
    return "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y.";
  }
}

export { generateAnswer };
